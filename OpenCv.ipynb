{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dl-colman/exercise-1/blob/main/OpenCv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyGpA4oCx1S5"
      },
      "source": [
        "# OpenCV\n",
        "OpenCV is a library of programming functions mainly aimed at real-time computer vision. Originally developed by Intel, it was later supported by Willow Garage then Itseez. The library is cross-platform and free for use under the open-source Apache 2 License.<br>\n",
        "\n",
        "<img width=\"335px\" src =\"https://brands.home-assistant.io/_/opencv/logo.png\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmnbluCwxaFi"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8Nwd-JByQeU"
      },
      "source": [
        "Importing the library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EI3omqqxcIZ"
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ouhw9TNqzPaS"
      },
      "source": [
        "Read image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3E-nqNvzVqr"
      },
      "source": [
        "img = cv2.imread('/content/drive/MyDrive/exercise-1/opencv_images/image.jpg')\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqrKuRU21zZa"
      },
      "source": [
        "Print image pixels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_MyBSti15l9"
      },
      "source": [
        "print(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOZCJvZ-2Pi-"
      },
      "source": [
        "Crop Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT8B6opn2RNN"
      },
      "source": [
        "croped_image = img[100:500, 100:500, :]\n",
        "cv2_imshow(croped_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1q3sxvOjXC8G"
      },
      "source": [
        "Read image as Gray scale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DwtFwolXJPp"
      },
      "source": [
        "img_gray = cv2.imread('/content/drive/MyDrive/exercise-1/opencv_images/image.jpg', 0)\n",
        "cv2_imshow(img_gray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O2NqVll3UQW"
      },
      "source": [
        "Split image to RGB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gtt71rze3e44"
      },
      "source": [
        "b, g, r = cv2.split(img)\n",
        "\n",
        "numpy_horizontal_concat = np.concatenate((b, g, r), axis=1)\n",
        "cv2_imshow(numpy_horizontal_concat)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbzK9OTn9WaJ"
      },
      "source": [
        "Split image to YUV. Y is the Luminnance of the image and U,V is the chrominance of the image (Color). U is the blue color and V is the red color."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCbHssM19Yag"
      },
      "source": [
        "img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
        "y, u, v = cv2.split(img)\n",
        "\n",
        "numpy_horizontal_concat = np.concatenate((y, u, v), axis=1)\n",
        "cv2_imshow(numpy_horizontal_concat)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld2CTCVx9vr6"
      },
      "source": [
        "Lighten the image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqxZILO8_URU"
      },
      "source": [
        "brighter_y = cv2.add(y, 80)\n",
        "brighter_u = cv2.add(u, 80)\n",
        "brighter_v = cv2.add(v, 80)\n",
        "\n",
        "brighter_yuv = cv2.merge((brighter_y, brighter_u, brighter_v))\n",
        "\n",
        "numpy_horizontal_concat = np.concatenate((img, brighter_yuv), axis=1)\n",
        "cv2_imshow(numpy_horizontal_concat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsF2VQFtAFY5"
      },
      "source": [
        "Darken the image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wkbD25oALzF"
      },
      "source": [
        "darker_y = cv2.add(y, -80)\n",
        "darker_u = cv2.add(u, -80)\n",
        "darker_v = cv2.add(v, -80)\n",
        "\n",
        "darker_yuv = cv2.merge((darker_y, darker_u, darker_v))\n",
        "\n",
        "numpy_horizontal_concat = np.concatenate((img, darker_yuv), axis=1)\n",
        "cv2_imshow(numpy_horizontal_concat)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AEePFqwNFVc"
      },
      "source": [
        "### Rotating the image\n",
        "<ul>\n",
        "  <li>center – The center coordinates of the image</li>\n",
        "  <li>Angle – The angle (in degrees) by which the image should be rotated</li>\n",
        "  <li>Scale – The scaling factor\n",
        " </li>\n",
        "</ul>\n",
        "<img width=\"400px\" src=\"https://media.geeksforgeeks.org/wp-content/uploads/20190904230758/Screenshot-2019-08-24-at-5.38.11-PM.png\">\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nQwO8HhUp5f"
      },
      "source": [
        "img_shape = img.shape\n",
        "print(img_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux79kOhoVMFl"
      },
      "source": [
        "h, w = img.shape[:2]\n",
        "print(f'height: {h}, width: {w}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2zsT8k8VxOf"
      },
      "source": [
        "# Calculating the center of the image\n",
        "center = (w // 2, h // 2)\n",
        "  \n",
        "# Generating a rotation matrix\n",
        "matrix = cv2.getRotationMatrix2D(center, -45, 1.0) \n",
        "  \n",
        "# Performing the affine transformation\n",
        "rotated = cv2.warpAffine(img, matrix, (w, h))\n",
        "cv2_imshow(rotated)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRCeEzowYztU"
      },
      "source": [
        "### Blur the image by Gaussian blur\n",
        "<ul>\n",
        "  <li>Choose kernel size </li>\n",
        "  <li>Choose Kernel standard deviation along X-axis (Choose 0 for now...)\n",
        " </li>\n",
        "  <li>Average every [ixel in the kernel (each color channel</li>\n",
        "  \n",
        "</ul>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKqAg3GyaJ6_"
      },
      "source": [
        "Gaussian = cv2.GaussianBlur(img, (15, 15), 0)\n",
        "cv2_imshow(Gaussian)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laO5pRW0chM8"
      },
      "source": [
        "Detect corner of an image using OpenCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itDG-xQKdKvm"
      },
      "source": [
        "box = cv2.imread('/content/drive/MyDrive/exercise-1/opencv_images/box.jpg')\n",
        "cv2_imshow(box)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5CAjtRdd-G_"
      },
      "source": [
        "# convert image to gray scale imag\n",
        "gray_box= cv2.cvtColor(box, cv2.COLOR_BGR2GRAY)\n",
        "cv2_imshow(gray_box)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yXCWJdTeMiZ"
      },
      "source": [
        "# detect corners with the goodFeaturesToTrack function.\n",
        "corners = cv2.goodFeaturesToTrack(gray_box, 27, 0.01, 10)\n",
        "corners = np.int0(corners)\n",
        "  \n",
        "# we iterate through each corner, \n",
        "# making a circle at each point that we think is a corner.\n",
        "for i in corners:\n",
        "    x, y = i.ravel()\n",
        "    cv2.circle(box, (x, y), 3, 255, -1)\n",
        "\n",
        "cv2_imshow(box)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNwxMThkfNcH"
      },
      "source": [
        "Face Detection with OpenCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXZxgdqNfRBh"
      },
      "source": [
        "faces_img = cv2.imread('/content/drive/MyDrive/exercise-1/opencv_images/faces.jpg')\n",
        "cv2_imshow(faces_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_unzq-afxq4"
      },
      "source": [
        "# Convert into grayscale\n",
        "gray_faces = cv2.cvtColor(faces_img, cv2.COLOR_BGR2GRAY)\n",
        "cv2_imshow(gray_faces)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWvf2L5hfrT9"
      },
      "source": [
        "# Load the cascade ((trained model))\n",
        "face_cascade = cv2.CascadeClassifier('/content/drive/MyDrive/exercise-1/opencv_images/haarcascade_frontalface_default.xml')\n",
        "# Detect faces\n",
        "faces = face_cascade.detectMultiScale(gray_faces, 1.1, 4)\n",
        "# Draw rectangle around the faces\n",
        "for (x, y, w, h) in faces:\n",
        "    cv2.rectangle(faces_img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "\n",
        "cv2_imshow(faces_img)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}